}
head(X)
X = data.frame()
for (i in 1:length(v)) {
Xi = v[1:i]
Yi = myvar(Xi) - var(Xi)
Yi_index = list(index = i, value = Yi)
X = rbind(X, Yi_index)
}
head(X)
X = data.frame()
for (i in 1:length(v)) {
Xi = v[1:i]
Yi = myvar(as.vector(Xi)) - var(Xi)
Yi_index = list(index = i, value = Yi)
X = rbind(X, Yi_index)
}
head(X)
myvar(c(1))
myvar(c(1,2))
head(v)
ggplot(X) +
geom_point(aes(x = index, y = value), color = "violet")
library(ggplot2)
X = data.frame()
for (i in 1:length(v)) {
Xi = v[1:i]
Yi = myvar(as.vector(Xi)) - var(Xi)
Yi_index = list(index = i, value = Yi)
X = rbind(X, Yi_index)
}
ggplot(X) +
geom_point(aes(x = index, y = value), color = "violet")
View(X)
View(X)
ggplot(X) +
geom_point(aes(x = index, y = value), color = "violet") +
theme_minimal()
ggplot(X) +
geom_point(aes(x = index, y = value), color = "#FF5733") +
theme_minimal()
ggplot(X) +
geom_point(aes(x = index, y = value), color = "#C70039") +
theme_minimal()
ggplot(X[2:nrow(X)]) +
geom_point(aes(x = index, y = value), color = "#C70039") +
theme_minimal()
ggplot(X[2:nrow(X),]) +
geom_point(aes(x = index, y = value), color = "#C70039") +
theme_minimal()
x = c(1, 2, 3)
x - t(x)
x - x
sapply(X = x, FUN = function(value) { value - x })
sapply(X = x, FUN = function(value, y) { value - y }, y = x)
sapply(X = x, FUN = function(value) { value - mean(x) })
sapply(X = x, FUN = function(value, y) { value - mean(y) }, y = x)
sapply(X = x, FUN = function(value, y) { value - mean(y) }, y = x)
a = sapply(X = x, FUN = function(value, y) { value - mean(y) }, y = x)
a
a^2
sqrt
sqrt(9)
sqrt(-9)
custom_varaince = function(x) {
mean_difference = sapply(X = x, FUN = function(value, y) { value - mean(y) }, y = x)
sum_mean_squared = sum(mean_difference^2)
return(sqrt(sum_mean_squared / (length(x)-1)))
}
custom_variance = function(x) {
mean_difference = sapply(X = x, FUN = function(value, y) { value - mean(y) }, y = x)
sum_mean_squared = sum(mean_difference^2)
return(sqrt(sum_mean_squared / (length(x)-1)))
}
custom_variance(c(1,2,3))
custom_variance(c(1,2,3))
var(c(1,2,3))
custom_variance(c(7.66,2.5414,3.543525))
var(c(7.66,2.5414,3.543525))
myvar(c(7.66,2.5414,3.543525))
x = c(7.66,2.5414,3.543525)
mean_difference = sapply(X = x, FUN = function(value, y) { value - mean(y) }, y = x)
head(mean_difference)
sum(mean_difference^2)
mean_difference^2
custom_variance = function(x) {
mean_difference = sapply(X = x, FUN = function(value, y) { value - mean(y) }, y = x)
sum_mean_squared = sum(mean_difference^2)
return(sqrt(sum_mean_squared / (length(x))))
}
custom_variance(c(7.66,2.5414,3.543525))
var(c(7.66,2.5414,3.543525))
custom_variance = function(x) {
mean_difference = sapply(X = x, FUN = function(value, y) { value - mean(y) }, y = x)
sum_mean_squared = sum(mean_difference^2)
return(sum_mean_squared / (length(x)))
}
custom_variance(c(7.66,2.5414,3.543525))
custom_variance = function(x) {
mean_difference = sapply(X = x, FUN = function(value, y) { value - mean(y) }, y = x)
sum_mean_squared = sum(mean_difference^2)
return(sum_mean_squared / (length(x)))
}
custom_variance(c(7.66,2.5414,3.543525))
var(c(7.66,2.5414,3.543525))
myvar(c(7.66,2.5414,3.543525))
custom_variance = function(x) {
mean_difference = sapply(X = x, FUN = function(value, y) { (value - mean(y))^2 }, y = x)
sum_mean_squared = sum(mean_difference)
return(sum_mean_squared / (length(x)))
}
custom_variance = function(x) {
mean_difference = sapply(X = x, FUN = function(value, y) { (value - mean(y))^2 }, y = x)
sum_mean_squared = sum(mean_difference)
return(sum_mean_squared / (length(x)))
}
custom_variance(c(7.66,2.5414,3.543525))
library(ggplot2)
knitr::opts_chunk$set(echo = TRUE)
data = csv2.read('tecator.csv')
data = read.csv2('tecator.csv')
library(ggplot2)
library(knitr)
knitr::opts_chunk$set(echo = TRUE)
data = read.csv2('tecator.csv')
kable(head(data))
kable(head(data[1,99,100]))
ncol(data)
data = read.csv2('tecator.csv')
data = read.csv2("tecator.csv", sep=",", dec=".")
data = read.csv2("tecator.csv", sep=",", dec=".")
kable(head(data[1,99,100]))
data = read.csv2("tecator.csv", sep=",", dec=".")
kable(head(data[c(1,99,100)]))
data = read.csv2("tecator.csv", sep=",", dec=".")
kable(head(data[c(1,103,104)]))
data = read.csv2("tecator.csv", sep=",", dec=".")
kable(head(data[c(1, 101, 102, 103, 104)]))
sequence = seq(from = 0, to = 100000, by = 1)
func = f(sequence)
deri = f_prime(sequence)
plot_data_frame = data.frame(sequence, func, deri)
sequence = seq(from = 0, to = 100000, by = 1)
func = f(sequence)
deri = f_prime(sequence)
df = data.frame(sequence, func, deri)
sequence = seq(from = 0, to = 100000, by = 1)
func = f(sequence)
deri = f_prime(sequence)
df = data.frame(sequence, func, deri)
ggplot(df) +
geom_point(aes(x = sequence, y = func), color = "#C70039") +
geom_point(aes(x = sequence, y = deri), color = "#FFC300") +
theme_minimal()
sequence = seq(from = 0, to = 100000, by = 1)
#func = f(sequence)
deri = f_prime(sequence)
df = data.frame(sequence, func, deri)
ggplot(df) +
#geom_point(aes(x = sequence, y = func), color = "#C70039") +
geom_point(aes(x = sequence, y = deri), color = "#FFC300") +
theme_minimal()
sequence = seq(from = 0, to = 20, by = 1)
#func = f(sequence)
deri = f_prime(sequence)
df = data.frame(sequence, deri)
ggplot(df) +
#geom_point(aes(x = sequence, y = func), color = "#C70039") +
geom_point(aes(x = sequence, y = deri), color = "#FFC300") +
theme_minimal()
sequence = seq(from = 0, to = 20, by = 1)
#func = f(sequence)
deri = f_prime(sequence)
df = data.frame(sequence, deri)
ggplot(df) +
#geom_point(aes(x = sequence, y = func), color = "#C70039") +
geom_line(aes(x = sequence, y = deri), color = "#FFC300") +
theme_minimal()
sequence = seq(from = 0, to = 20, by = 1)
#func = f(sequence)
deri = f_prime(sequence)
df = data.frame(sequence, deri)
ggplot(df) +
#geom_point(aes(x = sequence, y = func), color = "#C70039") +
geom_line(aes(x = sequence, y = deri), color = "#C70039") +
theme_minimal()
sequence = seq(from = 0, to = 200, by = 1)
#func = f(sequence)
deri = f_prime(sequence)
df = data.frame(sequence, deri)
ggplot(df) +
#geom_point(aes(x = sequence, y = func), color = "#C70039") +
geom_line(aes(x = sequence, y = deri), color = "#C70039") +
theme_minimal()
sequence = seq(from = 0, to = 20, by = 1)
#func = f(sequence)
deri = f_prime(sequence)
df = data.frame(sequence, deri)
ggplot(df) +
#geom_point(aes(x = sequence, y = func), color = "#C70039") +
geom_line(aes(x = sequence, y = deri), color = "#C70039") +
theme_minimal()
sequence = seq(from = 0, to = 20, by = 1)
func = f(sequence)
deri = f_prime(sequence)
df = data.frame(sequence, deri)
ggplot(df) +
geom_line(aes(x = sequence, y = deri), color = "#C70039") +
theme_minimal()
ggplot(df) +
geom_point(aes(x = sequence, y = func), color = "#C70039") +
theme_minimal()
sequence = seq(from = 0, to = 20, by = 1)
func = f(sequence)
deri = f_prime(sequence)
df = data.frame(sequence, deri)
ggplot(df) +
geom_line(aes(x = sequence, y = deri), color = "#C70039") +
theme_minimal()
ggplot(df) +
geom_line(aes(x = sequence, y = func), color = "#FFC300") +
theme_minimal()
X = data[c(1:102, 104),]
data = read.csv2("tecator.csv", sep=",", dec=".")
kable(head(data[c(1, 101, 102, 103, 104),]))
data = read.csv2("tecator.csv", sep=",", dec=".")
kable(head(data[, c(1, 101, 102, 103, 104)]))
X = data[, c(1:102, 104)]
head(X)
Y = data[, c(103)]
X = data[, c(1:102, 104)]
Y = data[, c(103)]
A = X %*% t(X)
X = data[, c(1:102, 104)]
Y = as.matrix(data[, c(103)])
A = X %*% t(X)
class(X)
X = as.matrix(data[, c(1:102, 104)])
Y = as.matrix(data[, c(103)])
A = X %*% t(X)
b = t(X) %*% Y
X = as.matrix(data[, c(1:102, 104)])
Y = as.matrix(data[, c(103)])
A = X %*% t(X)
b = t(X) %*% Y
beta = solve(A) %*% b
X = as.matrix(data[, c(1:102, 104)])
Y = as.matrix(data[, c(103)])
A = t(X) %*% X
b = t(X) %*% Y
beta = solve(A) %*% b
dim(A)
dim(b)
dim(solve(A))
kappa(A)
0.01 * 10000
1000 * 10000
if (!requireNamespace("BiocManager", quietly = TRUE))
install.packages("BiocManager")
library(bnlearn)
install.packages("bnlearn")
install.packages("btibble")
install.packages("tibble")
install.packages("gRain")
install.packages("parallel")
BiocManager::install("RBGL")
install.packages("dplyr")
install.packages("gRain")
install.packages("caret")
install.packages("parallel")
install.packages("e1071")
################################################################################
# Exercise 2)
################################################################################
asia = asia %>% mutate(id = row_number())
knitr::opts_chunk$set(echo = TRUE)
library(bnlearn)
library(tibble)
library(dplyr)
library(gRain)
library(caret)
library(parallel)
if (!requireNamespace("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install("RBGL")
set.seed(42)
################################################################################
# Exercise 2)
################################################################################
asia = asia %>% mutate(id = row_number())
train = asia %>% sample_frac(.8)
test = anti_join(asia, train, by = 'id')
train = select(train, -id)
test = select(test, -id)
testX = select(test, -S)
testY = test %>% select(S)
# Helper Functions
## Training the network
train_bayesian_network = function(structure = NULL,
data = train,
learning_algorithm = iamb,
...) {
# Network
if (is.null(structure)) {
bayesian_network = learning_algorithm(data, ...)
}
else {
bayesian_network = structure
}
# Parameters
bayesian_network_fit = bn.fit(bayesian_network, data)
bayesian_network_grain = as.grain(bayesian_network_fit)
return(list(bn_grain=bayesian_network_grain,
bn_fit=bayesian_network_fit,
bn_structure=bayesian_network))
}
## Predicting with the network
predict_bayesian_network = function(bayesian_network,
testX_ = testX,
testY_ = testY,
markov_blanket = NULL) {
# Parallel setup
no_cores = detectCores()
cl = makeCluster(no_cores)
clusterExport(cl, list("querygrain", "setEvidence", "bayesian_network"),
envir=environment())
# predict for each data point of the test data
if (!is.null(markov_blanket)) {
# When predicting, only use the nodes from the Markov Blanket
res = t(parApply(cl, testX, 1, FUN = function(x) {
return(querygrain(setEvidence(bayesian_network, markov_blanket,
x[markov_blanket]))$S)
}))
}
else {
# Predict using all nodes
res = t(parApply(cl, testX_, 1, FUN = function(x) {
return(querygrain(setEvidence(bayesian_network, names(x), x))$S)
}))
}
# Classify
pred = parApply(cl, res, 1, FUN = function(x) {
if (x[2] > 0.5) return("yes")
return("no")
})
# Factorise
testY_factor = testY_[,1]
pred_factor = factor(pred)
# Call to a library to calculate interesting metrics
confusion_matrix = confusionMatrix(pred_factor,
testY_factor, mode="everything")
stopCluster(cl)
return(list(res=res, pred=pred, cf=confusion_matrix))
}
bayesian_network = iamb(train)
bayesian_network
plot(bayesian_network)
esian_network_fit = bn.fit(bayesian_network, train)
besian_network_fit = bn.fit(bayesian_network, train)
besian_network_fit
besian_network_fit
bayesian_network_grain = as.grain(bayesian_network_fit)
besian_network_fit = bn.fit(bayesian_network, train)
bayesian_network_grain = as.grain(bayesian_network_fit)
beysian_network_fit = bn.fit(bayesian_network, train)
################################################################################
# Exercise 2)
################################################################################
asia = asia %>% mutate(id = row_number())
train = asia %>% sample_frac(.8)
test = anti_join(asia, train, by = 'id')
train = select(train, -id)
test = select(test, -id)
testX = select(test, -S)
testY = test %>% select(S)
# Helper Functions
## Training the network
train_bayesian_network = function(structure = NULL,
data = train,
learning_algorithm = iamb,
...) {
# Network
if (is.null(structure)) {
bayesian_network = learning_algorithm(data, ...)
}
else {
bayesian_network = structure
}
# Parameters
bayesian_network_fit = bn.fit(bayesian_network, data)
bayesian_network_grain = as.grain(bayesian_network_fit)
return(list(bn_grain=bayesian_network_grain,
bn_fit=bayesian_network_fit,
bn_structure=bayesian_network))
}
## Predicting with the network
predict_bayesian_network = function(bayesian_network,
testX_ = testX,
testY_ = testY,
markov_blanket = NULL) {
# Parallel setup
no_cores = detectCores()
cl = makeCluster(no_cores)
clusterExport(cl, list("querygrain", "setEvidence", "bayesian_network"),
envir=environment())
# predict for each data point of the test data
if (!is.null(markov_blanket)) {
# When predicting, only use the nodes from the Markov Blanket
res = t(parApply(cl, testX, 1, FUN = function(x) {
return(querygrain(setEvidence(bayesian_network, markov_blanket,
x[markov_blanket]))$S)
}))
}
else {
# Predict using all nodes
res = t(parApply(cl, testX_, 1, FUN = function(x) {
return(querygrain(setEvidence(bayesian_network, names(x), x))$S)
}))
}
# Classify
pred = parApply(cl, res, 1, FUN = function(x) {
if (x[2] > 0.5) return("yes")
return("no")
})
# Factorise
testY_factor = testY_[,1]
pred_factor = factor(pred)
# Call to a library to calculate interesting metrics
confusion_matrix = confusionMatrix(pred_factor,
testY_factor, mode="everything")
stopCluster(cl)
return(list(res=res, pred=pred, cf=confusion_matrix))
}
bn_2 = train_bayesian_network(structure = NULL,
data = train,
learning_algorithm = hc,
restart = 10,
score = "bic")
bn_2$bn_structure
bn_2$bn_fit
plot(bn_2$bn_fit)
plot(bn_2$bn_grain)
predicate_2 = predict_bayesian_network(bn_2$bn_grain)
# Metrics
predicate_2$cf
# We will use predict to compare our own inference with the build in version
predicate_2_sol = predict(bn_2$bn_fit, "S", data = test, method="bayes-lw")
# Factorize
testY_factor = testY[,1]
confusionMatrix(predicate_2_sol, testY_factor, mode="everything")
bn_2 = train_bayesian_network(structure = NULL,
data = train,
learning_algorithm = hc,
restart = 10,
score = "bic")
a = querygrain(setEvidence(bn_2$bn_grain, names(testX[1,]), testX[1,]))$S
a
a = querygrain(setEvidence(bn_2$bn_grain, names(testX[1,]), testX[1,]))
a
a = querygrain(setEvidence(bn_2$bn_grain, names(testX[1,]), testX[1,]))$S
a
a = querygrain(setEvidence(bn_2$bn_grain, names(testX[2,]), testX[2,]))$S
a
a = querygrain(setEvidence(bn_2$bn_grain, names(testX[3,]), testX[4,]))$S
a
testX[3, ]
testX[1, ]
testX[2, ]
querygrain(setEvidence(bn_2$bn_grain, names(testX[3,]), testX[3,]))$S
querygrain(setEvidence(bn_2$bn_grain, names(testX[5,]), testX[5,]))$S
querygrain(setEvidence(bn_2$bn_grain, names(testX[5,]), testX[5,]))$S
names(testX[5,])
testX[5,]
t(parApply(cl, testX_, 1, FUN = function(x) {
return(querygrain(setEvidence(bayesian_network, names(x), x))$S)
}))
t(apply(testX_, 1, FUN = function(x) {
return(querygrain(setEvidence(bayesian_network, names(x), x))$S)
}))
t(apply(testX, 1, FUN = function(x) {
return(querygrain(setEvidence(bayesian_network, names(x), x))$S)
}))
t(apply(testX, 1, FUN = function(x) {
return(querygrain(setEvidence(bn_2$bn_grain, names(x), x))$S)
}))
nrow(asia)
dim(testX)
dim(t(apply(testX, 1, FUN = function(x) {
return(querygrain(setEvidence(bn_2$bn_grain, names(x), x))$S)
})))
bn_2 = train_bayesian_network(structure = NULL,
data = train)
knitr::opts_chunk$set(echo = TRUE)
library(bnlearn)
library(tibble)
library(dplyr)
library(gRain)
library(caret)
library(parallel)
if (!requireNamespace("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install("RBGL")
knitr::opts_chunk$set(echo = TRUE)
library(bnlearn)
library(tibble)
library(dplyr)
library(gRain)
library(caret)
library(parallel)
if (!requireNamespace("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install("RBGL")
